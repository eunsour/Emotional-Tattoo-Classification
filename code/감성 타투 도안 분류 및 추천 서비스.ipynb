{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 폴더명 변경하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = './엣지/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['test', 'train', 'validation']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tattoo_categori_list = os.listdir(folder_path)\n",
    "tattoo_categori_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train, validation, test 셋트로 분리하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test 6\n",
      "train 6\n",
      "validation 6\n"
     ]
    }
   ],
   "source": [
    "tattoo_categori_list = os.listdir(folder_path)\n",
    "for folder_name in tattoo_categori_list :\n",
    "    print(folder_name, len(os.listdir(folder_path+folder_name)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5(train) : 2(validation) : 3(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./엣지/train\n",
      "./엣지/validation\n",
      "./엣지/test\n"
     ]
    }
   ],
   "source": [
    "train_path = os.path.join(folder_path,'train')\n",
    "validation_path = os.path.join(folder_path,'validation')\n",
    "test_path = os.path.join(folder_path,'test')\n",
    "print(train_path) \n",
    "print(validation_path)\n",
    "print(test_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### raw-image to numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageOps\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체 사진 불러오는 함수\n",
    "def load_images(folder_path,file_names,img_size_shape):\n",
    "    images = []                                          # 불러올 사진을 담을 리스트\n",
    "    \n",
    "    for i in range(len(file_names)):\n",
    "        path = os.path.join(folder_path,file_names[i])   # 사진경로 생성\n",
    "        img = Image.open(path).resize(img_size_shape)    # 이미지 오픈 후 리사이징\n",
    "        img = img.convert('RGB')                         # PNG -> RGB\n",
    "        images.append(np.array(img))                     # numpy배열로 변환 후 리스트에 추가\n",
    "   \n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['고래', '꽃', '나비', '달', '십자가', '하트']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tattoo_dir_list = os.listdir(train_path)   # 타투 폴더 이름 가져오기\n",
    "tattoo_dir_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "고래\n",
      "1513\n",
      "꽃\n",
      "2120\n",
      "나비\n",
      "2259\n",
      "달\n",
      "1281\n",
      "십자가\n",
      "1629\n",
      "하트\n",
      "1782\n"
     ]
    }
   ],
   "source": [
    "X_train = []\n",
    "y_train = []\n",
    "# train data\n",
    "for tattoo_dir in tattoo_dir_list :\n",
    "    print(tattoo_dir)\n",
    "    path = os.path.join(folder_path,'train',tattoo_dir)  # 경로 만들기\n",
    "    file_names = os.listdir(path)                        # 파일 이름 얻기\n",
    "    data = load_images(path, file_names, (224,224))      # 이미지 로드\n",
    "    print(len(data))\n",
    "    y_train = y_train + [tattoo_dir] * len(data)         # 정답 만들기\n",
    "    X_train = X_train + data                             # 이미지 병합\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10584, 224, 224, 3)\n",
      "(10584,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "고래\n",
      "605\n",
      "꽃\n",
      "848\n",
      "나비\n",
      "904\n",
      "달\n",
      "512\n",
      "십자가\n",
      "652\n",
      "하트\n",
      "713\n"
     ]
    }
   ],
   "source": [
    "X_validation = []\n",
    "y_validation = []\n",
    "# validation data\n",
    "for tattoo_dir in tattoo_dir_list :\n",
    "    print(tattoo_dir)\n",
    "    path = os.path.join(folder_path,'validation',tattoo_dir)     # 경로 만들기\n",
    "    file_names = os.listdir(path)                                # 파일 이름 얻기\n",
    "    data = load_images(path, file_names, (224,224))              # 이미지 로드\n",
    "    print(len(data))\n",
    "    y_validation = y_validation + [tattoo_dir] * len(data)       # 정답 만들기\n",
    "    X_validation = X_validation + data                           # 이미지 병합\n",
    "\n",
    "X_validation = np.array(X_validation)\n",
    "y_validation = np.array(y_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4234, 224, 224, 3)\n",
      "(4234,)\n"
     ]
    }
   ],
   "source": [
    "print(X_validation.shape)\n",
    "print(y_validation.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "고래\n",
      "908\n",
      "꽃\n",
      "1272\n",
      "나비\n",
      "1356\n",
      "달\n",
      "769\n",
      "십자가\n",
      "978\n",
      "하트\n",
      "1070\n"
     ]
    }
   ],
   "source": [
    "X_test = []\n",
    "y_test = []\n",
    "# test data\n",
    "for tattoo_dir in tattoo_dir_list :\n",
    "    print(tattoo_dir)\n",
    "    path = os.path.join(folder_path,'test',tattoo_dir)           # 경로 만들기\n",
    "    file_names = os.listdir(path)                                # 파일 이름 얻기\n",
    "    data = load_images(path, file_names, (224,224))              # 이미지 로드\n",
    "    print(len(data))\n",
    "    y_test = y_test + [tattoo_dir] * len(data)                   # 정답 만들기\n",
    "    X_test = X_test + data                                       # 이미지 병합\n",
    "\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6353, 224, 224, 3)\n",
      "(6353,)\n"
     ]
    }
   ],
   "source": [
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense,Conv2D,MaxPool2D,Dropout,Flatten, BatchNormalization, Activation\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,EarlyStopping\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_one_hot = pd.get_dummies(y_train)\n",
    "y_validation_one_hot = pd.get_dummies(y_validation)\n",
    "y_test_one_hot = pd.get_dummies(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv4 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv4 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv4 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "=================================================================\n",
      "Total params: 20,024,384\n",
      "Trainable params: 20,024,384\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.applications import VGG19\n",
    "\n",
    "conv_base = VGG19(weights='imagenet',\n",
    "                 include_top=False,\n",
    "                 input_shape=(224, 224, 3))\n",
    "print(conv_base.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg19 (Functional)           (None, 7, 7, 512)         20024384  \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               6422784   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 6)                 1542      \n",
      "=================================================================\n",
      "Total params: 26,448,710\n",
      "Trainable params: 26,448,710\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "36\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "vgg19_model = Sequential()\n",
    "vgg19_model.add(conv_base)\n",
    "vgg19_model.add(Flatten())\n",
    "vgg19_model.add(Dense(256,activation='relu'))\n",
    "vgg19_model.add(Dense(6,activation='softmax'))\n",
    "print(vgg19_model.summary())\n",
    "conv_base.trainable=True\n",
    "print(len(vgg19_model.trainable_weights))\n",
    "conv_base.trainable=False\n",
    "print(len(vgg19_model.trainable_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg19_model.compile(loss = 'categorical_crossentropy',\n",
    "             optimizer = 'adam',\n",
    "             metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./model/Tattoo_10_Model_{epoch:03d}_{val_accuracy:.4f}.hdf5\"\n",
    "mckp = ModelCheckpoint(filepath = path,\n",
    "                      monitor = 'val_accuracy',\n",
    "                      verbose=1,\n",
    "                      save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "212/212 [==============================] - ETA: 0s - loss: 1.7634e-04 - accuracy: 1.0000\n",
      "Epoch 00001: val_accuracy did not improve from 1.00000\n",
      "212/212 [==============================] - 46s 218ms/step - loss: 1.7634e-04 - accuracy: 1.0000 - val_loss: 3.5541e-04 - val_accuracy: 1.0000\n",
      "Epoch 2/7\n",
      "212/212 [==============================] - ETA: 0s - loss: 9.8182e-05 - accuracy: 1.0000\n",
      "Epoch 00002: val_accuracy did not improve from 1.00000\n",
      "212/212 [==============================] - 46s 218ms/step - loss: 9.8182e-05 - accuracy: 1.0000 - val_loss: 2.5706e-04 - val_accuracy: 1.0000\n",
      "Epoch 3/7\n",
      "212/212 [==============================] - ETA: 0s - loss: 7.1117e-05 - accuracy: 1.0000\n",
      "Epoch 00003: val_accuracy did not improve from 1.00000\n",
      "212/212 [==============================] - 46s 219ms/step - loss: 7.1117e-05 - accuracy: 1.0000 - val_loss: 2.2443e-04 - val_accuracy: 1.0000\n",
      "Epoch 4/7\n",
      "212/212 [==============================] - ETA: 0s - loss: 5.3427e-05 - accuracy: 1.0000\n",
      "Epoch 00004: val_accuracy did not improve from 1.00000\n",
      "212/212 [==============================] - 47s 220ms/step - loss: 5.3427e-05 - accuracy: 1.0000 - val_loss: 2.0294e-04 - val_accuracy: 1.0000\n",
      "Epoch 5/7\n",
      "212/212 [==============================] - ETA: 0s - loss: 4.4031e-05 - accuracy: 1.0000\n",
      "Epoch 00005: val_accuracy did not improve from 1.00000\n",
      "212/212 [==============================] - 47s 222ms/step - loss: 4.4031e-05 - accuracy: 1.0000 - val_loss: 1.6154e-04 - val_accuracy: 1.0000\n",
      "Epoch 6/7\n",
      "212/212 [==============================] - ETA: 0s - loss: 3.5996e-05 - accuracy: 1.0000\n",
      "Epoch 00006: val_accuracy did not improve from 1.00000\n",
      "212/212 [==============================] - 47s 224ms/step - loss: 3.5996e-05 - accuracy: 1.0000 - val_loss: 1.4943e-04 - val_accuracy: 1.0000\n",
      "Epoch 7/7\n",
      "212/212 [==============================] - ETA: 0s - loss: 3.0155e-05 - accuracy: 1.0000\n",
      "Epoch 00007: val_accuracy did not improve from 1.00000\n",
      "212/212 [==============================] - 47s 221ms/step - loss: 3.0155e-05 - accuracy: 1.0000 - val_loss: 1.4082e-04 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "vgg19_history = vgg19_model.fit(X_train,y_train_one_hot,\n",
    "         validation_data=(X_validation,y_validation_one_hot),\n",
    "         epochs = 7,\n",
    "         batch_size = 50,                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        \n",
    "         callbacks=[mckp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10,5)) # 가로,세로 사이즈\n",
    "plt.plot(vgg19_history.history['loss'], label='loss')\n",
    "plt.plot(vgg19_history.history['val_loss'], label='val_loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,5)) # 가로,세로 사이즈\n",
    "plt.plot(history2.history['accuracy'], label='accuracy')\n",
    "plt.plot(history2.history['val_accuracy'], label='val_accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 18s 91ms/step - loss: 2.4649e-04 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.00024649323313497007, 1.0]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg19_model.evaluate(X_test,y_test_one_hot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 로딩하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "best_model = load_model('./model/Tattoo_10_Model_002_1.0000.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.predict_classes(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.evaluate(X_test,y_test_one_hot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tattoo_dir_list = ['고래', '꽃', '나비', '달', '십자가', '하트']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0.12956251 0.12956251 0.35218737 0.12956251 0.12956251 0.12956251], shape=(6,), dtype=float32)\n",
      "\n",
      "This image most likely belongs to 나비 with a 35.22 percent confidence.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from PIL import Image, ImageOps\n",
    "\n",
    "PATH = './엣지엣지/butterfly_21.jpg'\n",
    "    \n",
    "img = Image.open(PATH).resize((224, 224))\n",
    "img_array = keras.preprocessing.image.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, 0)\n",
    "\n",
    "predictions = best_model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(score)\n",
    "print(\n",
    "    \"\\nThis image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(tattoo_dir_list[np.argmax(score)], 100 * np.max(score))\n",
    ")\n",
    "\n",
    "fold_name = tattoo_dir_list[np.argmax(score)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### image similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.73046875 > C:\\Users\\SM107\\3차 프로젝트\\추려추려\\나비\\0004.jpg\n",
      "0.7890625 > C:\\Users\\SM107\\3차 프로젝트\\추려추려\\나비\\0018.jpg\n",
      "0.80859375 > C:\\Users\\SM107\\3차 프로젝트\\추려추려\\나비\\0027.jpg\n",
      "0.8125 > C:\\Users\\SM107\\3차 프로젝트\\추려추려\\나비\\0001.jpg\n",
      "0.90625 > C:\\Users\\SM107\\3차 프로젝트\\추려추려\\나비\\0042.jpg\n",
      "ok\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os, re\n",
    "\n",
    "# 파일 경로 지정하기\n",
    "search_dir = os.getcwd() + \"\\\\추려추려\\\\\" + fold_name\n",
    "cache_dir = os.getcwd() + \"\\\\추려추려\\\\cache_avhash\"\n",
    "if not os.path.exists(cache_dir):\n",
    "    os.mkdir(cache_dir)\n",
    "\n",
    "# 이미지 데이터를 Average Hash로 변화하기\n",
    "def average_hash(fname,size=16):\n",
    "    fname2 = fname[len(search_dir):]\n",
    "    \n",
    "    #이미지 캐시하기\n",
    "    cache_file = cache_dir + \"\\\\\" + fname2.replace('\\\\','_') + \".csv\"\n",
    "    if not os.path.exists(cache_file):  # 해시 생성하기\n",
    "        img = Image.open(fname)\n",
    "        img = img.convert('L').resize((size, size), Image.ANTIALIAS)\n",
    "        pixels = np.array(img.getdata()).reshape((size, size))\n",
    "        avg = pixels.mean()\n",
    "        px = 1 * (pixels > avg)\n",
    "        np.savetxt(cache_file, px, fmt=\"%.0f\", delimiter=\",\")\n",
    "    else: \n",
    "        px = np.loadtxt(cache_file, delimiter=\",\")\n",
    "    return px\n",
    "\n",
    "#해밍 거리 구하기\n",
    "def hamming_dist(a,b):\n",
    "    aa = a.reshape(1,-1)      # 1차원 배열로 변환\n",
    "    ab = b.reshape(1,-1)\n",
    "    dist = (aa != ab).sum()\n",
    "    return dist\n",
    "\n",
    "# 모든 폴더의 이미지 파일에 처리 적용하기\n",
    "def enum_all_files(path):\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for f in files:\n",
    "            fname = os.path.join(root,f)\n",
    "            if re.search(r'\\.(jpg|jpeg|png)$',fname):\n",
    "                yield fname\n",
    "\n",
    "def fine_image(fname, rate):\n",
    "    src = average_hash(fname)\n",
    "\n",
    "    for fname in enum_all_files(search_dir):\n",
    "        dst = average_hash(fname)\n",
    "        diff_r = hamming_dist(src, dst) / 256\n",
    "        #print(\"[check]\",fname)\n",
    "        if diff_r < rate:\n",
    "            yield (diff_r,fname)\n",
    "\n",
    "# 찾기\n",
    "#srcfile = search_dir + \"\\\\whale_28.jpg\"\n",
    "srcfile = PATH\n",
    "html = \"\"\n",
    "sim = list(fine_image(srcfile, 1.5))\n",
    "sim = sorted(sim[:5], key=lambda x:x[0])\n",
    "\n",
    "image_addr = []\n",
    "# 비슷한 이미지를 찾은 결과(해밍거리 0.25 미만)를 이렇게 html파일로 만들어서 저장\n",
    "for r,f in sim:\n",
    "    print(r,\">\",f)\n",
    "    s = '<div style=\"float:left;\"><h3>[차이 :' + str(r) + '-' + \\\n",
    "        os.path.basename(f) + ']</h3>' + \\\n",
    "        '<p><a href= \"' + f + '\"><img src=\"'+f+'\"width=400>'+ \\\n",
    "        '</a></p></div>'\n",
    "    html += s\n",
    "    image_addr.append(f)\n",
    "\n",
    "#HTML로 출력\n",
    "html = \"\"\"<html><head><meta charset=\"utf8\"></head> \n",
    "<body><h3>원래 이미지</h3><p>\n",
    "<img src='{0}' width=400></p>{1}\n",
    "</body></html>\"\"\".format(srcfile, html)\n",
    "\n",
    "with open(\"./avhash-search-output.html\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(html)\n",
    "print(\"ok\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## flask 연동"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os, re\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow import keras\n",
    "from PIL import Image, ImageOps\n",
    "\n",
    "# 이미지 데이터를 Average Hash로 변화하기\n",
    "def average_hash(fname,size=16):\n",
    "    fname2 = fname[len(search_dir):]\n",
    "    \n",
    "    #이미지 캐시하기\n",
    "    cache_file = cache_dir + \"\\\\\" + fname2.replace('\\\\','_') + \".csv\"\n",
    "    if not os.path.exists(cache_file):  # 해시 생성하기\n",
    "        img = Image.open(fname)\n",
    "        img = img.convert('L').resize((size, size), Image.ANTIALIAS)\n",
    "        pixels = np.array(img.getdata()).reshape((size, size))\n",
    "        avg = pixels.mean()\n",
    "        px = 1 * (pixels > avg)\n",
    "        np.savetxt(cache_file, px, fmt=\"%.0f\", delimiter=\",\")\n",
    "    else: \n",
    "        px = np.loadtxt(cache_file, delimiter=\",\")\n",
    "    return px\n",
    "\n",
    "#해밍 거리 구하기\n",
    "def hamming_dist(a,b):\n",
    "    aa = a.reshape(1,-1)      # 1차원 배열로 변환\n",
    "    ab = b.reshape(1,-1)\n",
    "    dist = (aa != ab).sum()\n",
    "    return dist\n",
    "\n",
    "# 모든 폴더의 이미지 파일에 처리 적용하기\n",
    "def enum_all_files(path):\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for f in files:\n",
    "            fname = os.path.join(root,f)\n",
    "            if re.search(r'\\.(jpg|jpeg|png)$',fname):\n",
    "                yield fname\n",
    "\n",
    "def fine_image(fname, rate):\n",
    "    src = average_hash(fname)\n",
    "\n",
    "    for fname in enum_all_files(search_dir):\n",
    "        dst = average_hash(fname)\n",
    "        diff_r = hamming_dist(src, dst) / 256\n",
    "        #print(\"[check]\",fname)\n",
    "        if diff_r < rate:\n",
    "            yield (diff_r,fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "   WARNING: This is a development server. Do not use it in a production deployment.\n",
      "   Use a production WSGI server instead.\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://localhost:9000/ (Press CTRL+C to quit)\n",
      "127.0.0.1 - - [26/Nov/2020 12:17:56] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [26/Nov/2020 12:17:56] \"\u001b[33mGET /엣지엣지/butterfly_21.jpg HTTP/1.1\u001b[0m\" 404 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002657A114B70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [26/Nov/2020 12:18:22] \"\u001b[32mGET /painting?file_name=myPainting%20(21)4.jpg HTTP/1.1\u001b[0m\" 302 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0.35218745 0.12956253 0.12956253 0.12956253 0.12956253 0.12956253], shape=(6,), dtype=float32)\n",
      "\n",
      "This image most likely belongs to 고래 with a 35.22 percent confidence.\n",
      "고래\n",
      "./추려추려/고래\n",
      "0.23046875 > ./추려추려/고래\\0004.jpg\n",
      "0.26171875 > ./추려추려/고래\\0051.jpg\n",
      "0.28125 > ./추려추려/고래\\0059.jpg\n",
      "0.3125 > ./추려추려/고래\\0005.jpg\n",
      "0.328125 > ./추려추려/고래\\0042.jpg\n",
      "ok\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000266F1D7ABF8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "tf.Tensor([0.12956251 0.12956251 0.12956251 0.12956251 0.12956251 0.35218742], shape=(6,), dtype=float32)\n",
      "\n",
      "This image most likely belongs to 하트 with a 35.22 percent confidence.\n",
      "하트\n",
      "./추려추려/하트\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [26/Nov/2020 12:19:05] \"\u001b[32mGET /painting?file_name=myPainting%20(25)1.jpg HTTP/1.1\u001b[0m\" 302 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19921875 > ./추려추려/하트\\0003.jpg\n",
      "0.20703125 > ./추려추려/하트\\0001.jpg\n",
      "0.20703125 > ./추려추려/하트\\0002.jpg\n",
      "0.3046875 > ./추려추려/하트\\0004.jpg\n",
      "0.32421875 > ./추려추려/하트\\0005.jpg\n",
      "ok\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [26/Nov/2020 12:19:06] \"\u001b[37mGET /draw?img_url=./추려추려/하트\\0001.jpg HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [26/Nov/2020 12:19:06] \"\u001b[37mGET /draw?img_url=./추려추려/하트\\0003.jpg HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [26/Nov/2020 12:19:06] \"\u001b[37mGET /draw?img_url=./추려추려/하트\\0002.jpg HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [26/Nov/2020 12:19:06] \"\u001b[37mGET /draw?img_url=./추려추려/하트\\0004.jpg HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [26/Nov/2020 12:19:06] \"\u001b[37mGET /draw?img_url=./추려추려/하트\\0005.jpg HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:7 out of the last 7 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000026700F33D08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "tf.Tensor([0.12956251 0.12956251 0.12956251 0.35218737 0.12956251 0.12956251], shape=(6,), dtype=float32)\n",
      "\n",
      "This image most likely belongs to 달 with a 35.22 percent confidence.\n",
      "달\n",
      "./추려추려/달\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [26/Nov/2020 12:19:25] \"\u001b[32mGET /painting?file_name=myPainting%20(26).jpg HTTP/1.1\u001b[0m\" 302 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15625 > ./추려추려/달\\0047.jpg\n",
      "0.16015625 > ./추려추려/달\\0029.jpg\n",
      "0.16796875 > ./추려추려/달\\0022.jpg\n",
      "0.23046875 > ./추려추려/달\\0010.jpg\n",
      "0.25390625 > ./추려추려/달\\0015.jpg\n",
      "ok\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [26/Nov/2020 12:19:25] \"\u001b[37mGET /draw?img_url=./추려추려/달\\0047.jpg HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [26/Nov/2020 12:19:25] \"\u001b[37mGET /draw?img_url=./추려추려/달\\0029.jpg HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [26/Nov/2020 12:19:25] \"\u001b[37mGET /draw?img_url=./추려추려/달\\0022.jpg HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [26/Nov/2020 12:19:25] \"\u001b[37mGET /draw?img_url=./추려추려/달\\0015.jpg HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [26/Nov/2020 12:19:25] \"\u001b[37mGET /draw?img_url=./추려추려/달\\0010.jpg HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:8 out of the last 8 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000026710B84EA0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "tf.Tensor([0.13055666 0.3425506  0.13055666 0.13370791 0.13055666 0.13207164], shape=(6,), dtype=float32)\n",
      "\n",
      "This image most likely belongs to 꽃 with a 34.26 percent confidence.\n",
      "꽃\n",
      "./추려추려/꽃\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [26/Nov/2020 12:22:11] \"\u001b[32mGET /painting?file_name=myPainting%20(27).jpg HTTP/1.1\u001b[0m\" 302 -\n",
      "127.0.0.1 - - [26/Nov/2020 12:22:11] \"\u001b[37mGET /draw?img_url=./추려추려/꽃\\0011.jpg HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14453125 > ./추려추려/꽃\\0011.jpg\n",
      "0.15234375 > ./추려추려/꽃\\0038.jpg\n",
      "0.16015625 > ./추려추려/꽃\\0029.jpg\n",
      "0.19921875 > ./추려추려/꽃\\0006.jpg\n",
      "0.37109375 > ./추려추려/꽃\\0005.jpg\n",
      "ok\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [26/Nov/2020 12:22:12] \"\u001b[37mGET /draw?img_url=./추려추려/꽃\\0038.jpg HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [26/Nov/2020 12:22:12] \"\u001b[37mGET /draw?img_url=./추려추려/꽃\\0006.jpg HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [26/Nov/2020 12:22:12] \"\u001b[37mGET /draw?img_url=./추려추려/꽃\\0029.jpg HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [26/Nov/2020 12:22:12] \"\u001b[37mGET /draw?img_url=./추려추려/꽃\\0005.jpg HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:9 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000026561E700D0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [26/Nov/2020 12:24:00] \"\u001b[32mGET /painting?file_name=myPainting%20(28).jpg HTTP/1.1\u001b[0m\" 302 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0.12956253 0.12956253 0.12956253 0.35218745 0.12956253 0.12956253], shape=(6,), dtype=float32)\n",
      "\n",
      "This image most likely belongs to 달 with a 35.22 percent confidence.\n",
      "달\n",
      "./추려추려/달\n",
      "0.27734375 > ./추려추려/달\\0022.jpg\n",
      "0.28515625 > ./추려추려/달\\0010.jpg\n",
      "0.28515625 > ./추려추려/달\\0029.jpg\n",
      "0.2890625 > ./추려추려/달\\0047.jpg\n",
      "0.30859375 > ./추려추려/달\\0015.jpg\n",
      "ok\n",
      "WARNING:tensorflow:10 out of the last 10 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000026700F33378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [26/Nov/2020 12:24:27] \"\u001b[32mGET /painting?file_name=myPainting%20(29).jpg HTTP/1.1\u001b[0m\" 302 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0.13708018 0.13708007 0.13708007 0.1379597  0.21820395 0.23259604], shape=(6,), dtype=float32)\n",
      "\n",
      "This image most likely belongs to 하트 with a 23.26 percent confidence.\n",
      "하트\n",
      "./추려추려/하트\n",
      "0.1953125 > ./추려추려/하트\\0003.jpg\n",
      "0.21875 > ./추려추려/하트\\0002.jpg\n",
      "0.234375 > ./추려추려/하트\\0001.jpg\n",
      "0.31640625 > ./추려추려/하트\\0004.jpg\n",
      "0.3671875 > ./추려추려/하트\\0005.jpg\n",
      "ok\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000026551C3EE18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [26/Nov/2020 12:25:14] \"\u001b[32mGET /painting?file_name=myPainting%20(30).jpg HTTP/1.1\u001b[0m\" 302 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0.12956251 0.12956251 0.12956251 0.12956251 0.12956251 0.35218742], shape=(6,), dtype=float32)\n",
      "\n",
      "This image most likely belongs to 하트 with a 35.22 percent confidence.\n",
      "하트\n",
      "./추려추려/하트\n",
      "0.296875 > ./추려추려/하트\\0001.jpg\n",
      "0.296875 > ./추려추려/하트\\0002.jpg\n",
      "0.3203125 > ./추려추려/하트\\0003.jpg\n",
      "0.375 > ./추려추려/하트\\0005.jpg\n",
      "0.37890625 > ./추려추려/하트\\0004.jpg\n",
      "ok\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000026561F31C80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [26/Nov/2020 12:25:30] \"\u001b[32mGET /painting?file_name=myPainting%20(31).jpg HTTP/1.1\u001b[0m\" 302 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0.29745942 0.13438928 0.134423   0.16486117 0.13438518 0.1344819 ], shape=(6,), dtype=float32)\n",
      "\n",
      "This image most likely belongs to 고래 with a 29.75 percent confidence.\n",
      "고래\n",
      "./추려추려/고래\n",
      "0.2578125 > ./추려추려/고래\\0059.jpg\n",
      "0.26953125 > ./추려추려/고래\\0051.jpg\n",
      "0.2890625 > ./추려추려/고래\\0042.jpg\n",
      "0.375 > ./추려추려/고래\\0005.jpg\n",
      "0.37890625 > ./추려추려/고래\\0004.jpg\n",
      "ok\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002656E3DF268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "tf.Tensor([0.12991723 0.34878898 0.12991723 0.13153456 0.12991723 0.12992483], shape=(6,), dtype=float32)\n",
      "\n",
      "This image most likely belongs to 꽃 with a 34.88 percent confidence.\n",
      "꽃\n",
      "./추려추려/꽃\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [26/Nov/2020 12:28:06] \"\u001b[32mGET /painting?file_name=myPainting%20(32).jpg HTTP/1.1\u001b[0m\" 302 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2265625 > ./추려추려/꽃\\0006.jpg\n",
      "0.234375 > ./추려추려/꽃\\0011.jpg\n",
      "0.2578125 > ./추려추려/꽃\\0038.jpg\n",
      "0.2734375 > ./추려추려/꽃\\0029.jpg\n",
      "0.3203125 > ./추려추려/꽃\\0005.jpg\n",
      "ok\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002656FDCB378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [26/Nov/2020 12:29:47] \"\u001b[32mGET /painting?file_name=myPainting%20(33).jpg HTTP/1.1\u001b[0m\" 302 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0.12958401 0.12958746 0.12962943 0.12962931 0.12958656 0.35198322], shape=(6,), dtype=float32)\n",
      "\n",
      "This image most likely belongs to 하트 with a 35.20 percent confidence.\n",
      "하트\n",
      "./추려추려/하트\n",
      "0.09375 > ./추려추려/하트\\0002.jpg\n",
      "0.171875 > ./추려추려/하트\\0003.jpg\n",
      "0.1875 > ./추려추려/하트\\0001.jpg\n",
      "0.27734375 > ./추려추려/하트\\0004.jpg\n",
      "0.375 > ./추려추려/하트\\0005.jpg\n",
      "ok\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000026574B59A60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [26/Nov/2020 12:30:43] \"\u001b[32mGET /painting?file_name=myPainting%20(34).jpg HTTP/1.1\u001b[0m\" 302 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0.12956251 0.12956254 0.12956251 0.12956251 0.12956251 0.35218734], shape=(6,), dtype=float32)\n",
      "\n",
      "This image most likely belongs to 하트 with a 35.22 percent confidence.\n",
      "하트\n",
      "./추려추려/하트\n",
      "0.08984375 > ./추려추려/하트\\0002.jpg\n",
      "0.19140625 > ./추려추려/하트\\0001.jpg\n",
      "0.19921875 > ./추려추려/하트\\0003.jpg\n",
      "0.2578125 > ./추려추려/하트\\0004.jpg\n",
      "0.42578125 > ./추려추려/하트\\0005.jpg\n",
      "ok\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002656E3DF598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [26/Nov/2020 12:30:59] \"\u001b[32mGET /painting?file_name=myPainting%20(32)1.jpg HTTP/1.1\u001b[0m\" 302 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0.12991723 0.34878898 0.12991723 0.13153456 0.12991723 0.12992483], shape=(6,), dtype=float32)\n",
      "\n",
      "This image most likely belongs to 꽃 with a 34.88 percent confidence.\n",
      "꽃\n",
      "./추려추려/꽃\n",
      "0.2265625 > ./추려추려/꽃\\0006.jpg\n",
      "0.234375 > ./추려추려/꽃\\0011.jpg\n",
      "0.2578125 > ./추려추려/꽃\\0038.jpg\n",
      "0.2734375 > ./추려추려/꽃\\0029.jpg\n",
      "0.3203125 > ./추려추려/꽃\\0005.jpg\n",
      "ok\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000026551C3EE18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [26/Nov/2020 12:31:25] \"\u001b[32mGET /painting?file_name=myPainting%20(35).jpg HTTP/1.1\u001b[0m\" 302 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0.12956251 0.12956251 0.12956251 0.12956251 0.12956251 0.35218742], shape=(6,), dtype=float32)\n",
      "\n",
      "This image most likely belongs to 하트 with a 35.22 percent confidence.\n",
      "하트\n",
      "./추려추려/하트\n",
      "0.140625 > ./추려추려/하트\\0002.jpg\n",
      "0.171875 > ./추려추려/하트\\0001.jpg\n",
      "0.1953125 > ./추려추려/하트\\0003.jpg\n",
      "0.26171875 > ./추려추려/하트\\0004.jpg\n",
      "0.3671875 > ./추려추려/하트\\0005.jpg\n",
      "ok\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002656FDCB488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [26/Nov/2020 12:31:48] \"\u001b[32mGET /painting?file_name=myPainting%20(36).jpg HTTP/1.1\u001b[0m\" 302 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0.1295667  0.12956963 0.1295667  0.12958257 0.1295667  0.35214773], shape=(6,), dtype=float32)\n",
      "\n",
      "This image most likely belongs to 하트 with a 35.21 percent confidence.\n",
      "하트\n",
      "./추려추려/하트\n",
      "0.125 > ./추려추려/하트\\0002.jpg\n",
      "0.1484375 > ./추려추려/하트\\0001.jpg\n",
      "0.2265625 > ./추려추려/하트\\0003.jpg\n",
      "0.26953125 > ./추려추려/하트\\0004.jpg\n",
      "0.40625 > ./추려추려/하트\\0005.jpg\n",
      "ok\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002656E5BA268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [26/Nov/2020 12:33:52] \"\u001b[32mGET /painting?file_name=myPainting%20(37).jpg HTTP/1.1\u001b[0m\" 302 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0.13045754 0.13043751 0.13043751 0.34368256 0.13454707 0.13043788], shape=(6,), dtype=float32)\n",
      "\n",
      "This image most likely belongs to 달 with a 34.37 percent confidence.\n",
      "달\n",
      "./추려추려/달\n",
      "0.21484375 > ./추려추려/달\\0010.jpg\n",
      "0.2421875 > ./추려추려/달\\0047.jpg\n",
      "0.24609375 > ./추려추려/달\\0029.jpg\n",
      "0.25390625 > ./추려추려/달\\0022.jpg\n",
      "0.28515625 > ./추려추려/달\\0015.jpg\n",
      "ok\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000267026432F0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [26/Nov/2020 12:34:36] \"\u001b[32mGET /painting?file_name=myPainting%20(38).jpg HTTP/1.1\u001b[0m\" 302 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0.12968104 0.12966403 0.1300986  0.3512214  0.12966403 0.12967089], shape=(6,), dtype=float32)\n",
      "\n",
      "This image most likely belongs to 달 with a 35.12 percent confidence.\n",
      "달\n",
      "./추려추려/달\n",
      "0.18359375 > ./추려추려/달\\0022.jpg\n",
      "0.18359375 > ./추려추려/달\\0029.jpg\n",
      "0.1875 > ./추려추려/달\\0047.jpg\n",
      "0.22265625 > ./추려추려/달\\0010.jpg\n",
      "0.23046875 > ./추려추려/달\\0015.jpg\n",
      "ok\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002656FD309D8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "tf.Tensor([0.12976204 0.12976621 0.35029545 0.12986012 0.1305545  0.12976162], shape=(6,), dtype=float32)\n",
      "\n",
      "This image most likely belongs to 나비 with a 35.03 percent confidence.\n",
      "나비\n",
      "./추려추려/나비\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [26/Nov/2020 12:35:18] \"\u001b[32mGET /painting?file_name=myPainting%20(39).jpg HTTP/1.1\u001b[0m\" 302 -\n",
      "127.0.0.1 - - [26/Nov/2020 12:35:18] \"\u001b[37mGET /draw?img_url=./추려추려/나비\\0042.jpg HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16796875 > ./추려추려/나비\\0042.jpg\n",
      "0.171875 > ./추려추려/나비\\0027.jpg\n",
      "0.25390625 > ./추려추려/나비\\0001.jpg\n",
      "0.26953125 > ./추려추려/나비\\0018.jpg\n",
      "0.3515625 > ./추려추려/나비\\0004.jpg\n",
      "ok\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [26/Nov/2020 12:35:18] \"\u001b[37mGET /draw?img_url=./추려추려/나비\\0027.jpg HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [26/Nov/2020 12:35:18] \"\u001b[37mGET /draw?img_url=./추려추려/나비\\0001.jpg HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [26/Nov/2020 12:35:18] \"\u001b[37mGET /draw?img_url=./추려추려/나비\\0018.jpg HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [26/Nov/2020 12:35:18] \"\u001b[37mGET /draw?img_url=./추려추려/나비\\0004.jpg HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000026710BA51E0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [26/Nov/2020 14:42:45] \"\u001b[32mGET /painting?file_name=myPainting%20(21)5.jpg HTTP/1.1\u001b[0m\" 302 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0.35218745 0.12956253 0.12956253 0.12956253 0.12956253 0.12956253], shape=(6,), dtype=float32)\n",
      "\n",
      "This image most likely belongs to 고래 with a 35.22 percent confidence.\n",
      "고래\n",
      "./추려추려/고래\n",
      "0.23046875 > ./추려추려/고래\\0004.jpg\n",
      "0.26171875 > ./추려추려/고래\\0051.jpg\n",
      "0.28125 > ./추려추려/고래\\0059.jpg\n",
      "0.3125 > ./추려추려/고래\\0005.jpg\n",
      "0.328125 > ./추려추려/고래\\0042.jpg\n",
      "ok\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, redirect, url_for, request, Response, render_template\n",
    "from flask import send_file\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/draw/flower', methods = ['POST', 'GET'])\n",
    "def draw():\n",
    "    num = 3\n",
    "    \n",
    "    return send_file('./추려추려/' + str(num) + '.jpg', mimetype='image/jpeg')\n",
    "\n",
    "@app.route('/draw', methods = ['POST', 'GET'])\n",
    "def draw2():\n",
    "\n",
    "    return send_file(request.args['img_url'], mimetype='image/jpeg')\n",
    "\n",
    "@app.route('/', methods = ['POST', 'GET'])\n",
    "def home():\n",
    "    return render_template('avhash-search-output.html') #localhost:9000 기본 서버 열었을 때 템플릿으로 이동 아무것도 없는 껍데기\n",
    "\n",
    "\n",
    "#자바 서블릿단에서 파일명 받아와서 동작하는 함수\n",
    "@app.route('/painting', methods = ['POST', 'GET'])\n",
    "def painting():\n",
    "    file_name = request.args['file_name']\n",
    " \n",
    "    #PATH = './엣지엣지/butterfly_21.jpg' ## 사용자가 그린 도안의 경로 넣기 자바에서 값을 어떻게 불러오지 변수가 있어야됨. 고정경로+이미지명\n",
    "    PATH = r'C:\\Users\\SM120\\Desktop\\Re\\.metadata\\.plugins\\org.eclipse.wst.server.core\\tmp0\\wtpwebapps\\Tattoo\\upload\\{}'.format(file_name)\n",
    "\n",
    "        # 이미지 데이터를 Average Hash로 변화하기\n",
    "    def average_hash(fname,size=16):\n",
    "        fname2 = fname[len(search_dir):]\n",
    "\n",
    "        #이미지 캐시하기\n",
    "        cache_file = cache_dir + \"\\\\\" + fname2.replace('\\\\','_') + \".csv\"\n",
    "        if not os.path.exists(cache_file):  # 해시 생성하기\n",
    "            img = Image.open(fname)\n",
    "            img = img.convert('L').resize((size, size), Image.ANTIALIAS)\n",
    "            pixels = np.array(img.getdata()).reshape((size, size))\n",
    "            avg = pixels.mean()\n",
    "            px = 1 * (pixels > avg)\n",
    "            np.savetxt(cache_file, px, fmt=\"%.0f\", delimiter=\",\")\n",
    "        else: \n",
    "            px = np.loadtxt(cache_file, delimiter=\",\")\n",
    "        return px\n",
    "\n",
    "    #해밍 거리 구하기\n",
    "    def hamming_dist(a,b):\n",
    "        aa = a.reshape(1,-1)      # 1차원 배열로 변환\n",
    "        ab = b.reshape(1,-1)\n",
    "        dist = (aa != ab).sum()\n",
    "        return dist\n",
    "\n",
    "    # 모든 폴더의 이미지 파일에 처리 적용하기\n",
    "    def enum_all_files(path):\n",
    "        for root, dirs, files in os.walk(path):\n",
    "            for f in files:\n",
    "                fname = os.path.join(root,f)\n",
    "                if re.search(r'\\.(jpg|jpeg|png)$',fname):\n",
    "                    yield fname\n",
    "\n",
    "    def fine_image(fname, rate):\n",
    "        src = average_hash(fname)\n",
    "\n",
    "        for fname in enum_all_files(search_dir):\n",
    "            dst = average_hash(fname)\n",
    "            diff_r = hamming_dist(src, dst) / 256\n",
    "            #print(\"[check]\",fname)\n",
    "            if diff_r < rate:\n",
    "                yield (diff_r,fname)\n",
    "\n",
    "            \n",
    "    img = Image.open(PATH).resize((224, 224))\n",
    "    img_array = keras.preprocessing.image.img_to_array(img)\n",
    "    img_array = tf.expand_dims(img_array, 0)\n",
    "\n",
    "    tattoo_dir_list = ['고래', '꽃', '나비', '달', '십자가', '하트']\n",
    "\n",
    "    best_model = load_model('./model/Tattoo_10_Model_002_1.0000.hdf5')\n",
    "    predictions = best_model.predict(img_array)\n",
    "    score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "    print(score)\n",
    "    print(\n",
    "        \"\\nThis image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "        .format(tattoo_dir_list[np.argmax(score)], 100 * np.max(score))\n",
    "    )\n",
    "\n",
    "    fold_name = tattoo_dir_list[np.argmax(score)]   \n",
    "    print(fold_name)\n",
    "\n",
    "    # 파일 경로 지정하기\n",
    "    #search_dir = './templates/' + fold_name\n",
    "    search_dir = './추려추려/' + fold_name\n",
    "    print(search_dir) #추려추려/이름\n",
    "    cache_dir = './추려추려/cache_avhash'\n",
    "\n",
    "    if not os.path.exists(cache_dir):\n",
    "        os.mkdir(cache_dir)\n",
    "        \n",
    "    # 찾기\n",
    "    srcfile = PATH\n",
    "    html = \"\"\n",
    "    sim = list(fine_image(srcfile, 1.5))\n",
    "    sim = sorted(sim[:5], key=lambda x:x[0])\n",
    "\n",
    "    image_addr = [] \n",
    "    # 비슷한 이미지를 찾은 결과(해밍거리 0.25 미만)를 이렇게 html파일로 만들어서 저장\n",
    "    for r,f in sim:\n",
    "        print(r,\">\",f)\n",
    "        s = '<div style=\"float:left;\"><h3>[차이 :' + str(r) + '-' + \\\n",
    "            os.path.basename(f) + ']</h3>' + \\\n",
    "            '<p><a href= \"' + f + '\"><img src=\"'+f+'\"width=400>'+ \\\n",
    "            '</a></p></div>'\n",
    "        html += s\n",
    "        image_addr.append(f)\n",
    "        \n",
    "\n",
    "    #HTML로 출력\n",
    "    html = \"\"\"<html><head><meta charset=\"utf8\"></head> \n",
    "    <body><h3>원래 이미지</h3><p>\n",
    "    <img src='{0}' width=400></p>{1}\n",
    "    </body></html>\"\"\".format(srcfile, html)\n",
    "\n",
    "    with open(\"./avhash-search-output.html\", \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(html)\n",
    "    print(\"ok\") #여기까지 잘 됨.\n",
    "\n",
    "    \n",
    "    #이 주소가 아니라 다른 다른 \n",
    "    #return render_template('avhash-search-output.html')\n",
    "\n",
    "    #http://localhost:9000/painting?file_name={}.format(file_name)  이 주소로 이동하면서 사진도 띄워야됨\n",
    "\n",
    "    # redirect로  값을 반환해주는 페이지 이동하면서 이미지도 가져감..  쿼리스트링으로 배열은 못넘기고 대신 ,를 써서 join으로넘김\n",
    "    # cnn.result 로 가려면 저기 주소 바꿔야한다.\n",
    "    return redirect('http://localhost:8088/Tattoo/avhash-search-output.jsp?file_name={}'.format(\",\".join(image_addr)))\n",
    "    \n",
    "    print(\"ok2\")\n",
    "\n",
    "\n",
    "    \n",
    "# 무조건 맨 마지막    \n",
    "if __name__ == \"__main__\":\n",
    "    app.run(host=\"localhost\", port=\"9000\")   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
